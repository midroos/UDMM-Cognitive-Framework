{"episode": 0, "reward": 8.2, "steps": 19, "success": "Goal Reached", "identity": {"curiosity": 1.0, "consistency": 0.5650000000000001, "risk_tolerance": 1.0, "goal_alignment": 0.6752520962451583, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 1, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": -0.3, "consistency": 0.03, "goal_alignment": 0.22}}
{"episode": 1, "reward": -195.2999999999999, "steps": 74, "success": "Goal Reached", "identity": {"curiosity": 1.0, "consistency": 0.5798200000000001, "risk_tolerance": 0.9594, "goal_alignment": 0.6870006305142065, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 2, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": -0.26, "consistency": 0.02, "goal_alignment": 0.21}}
{"episode": 2, "reward": -46.10000000000005, "steps": 67, "success": "Goal Reached", "identity": {"curiosity": 1.0, "consistency": 0.5944603600000001, "risk_tolerance": 0.9192812, "goal_alignment": 0.6994613181307001, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 3, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": -0.22, "consistency": 0.01, "goal_alignment": 0.2}}
{"episode": 3, "reward": -195.9999999999987, "steps": 378, "success": "Goal Reached", "identity": {"curiosity": 1.0, "consistency": 0.6089214392800001, "risk_tolerance": 0.8796426375999999, "goal_alignment": 0.7022342092199289, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 4, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, consistent, goal-oriented", "narrative": "I act as an explore agent because I am curious, risk-taker, consistent, goal-oriented.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": -0.18, "consistency": -0.01, "goal_alignment": 0.2}}
{"episode": 4, "reward": -218.29999999999754, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9655, "consistency": 0.5968035964014401, "risk_tolerance": 0.8404833523248, "goal_alignment": 0.6610938917448852, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 5, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.17, "risk_tolerance": -0.14, "consistency": 0.0, "goal_alignment": 0.24}}
{"episode": 5, "reward": -337.10000000000366, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 1.0, "consistency": 0.5848349892086373, "risk_tolerance": 0.8018023856201504, "goal_alignment": 0.6204622699991312, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 6, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": -0.1, "consistency": 0.02, "goal_alignment": 0.28}}
{"episode": 6, "reward": -129.199999999999, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 1.0, "consistency": 0.57301531923022, "risk_tolerance": 0.7635987808489101, "goal_alignment": 0.5803383265915466, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 7, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": -0.06, "consistency": 0.03, "goal_alignment": 0.32}}
{"episode": 7, "reward": -614.3000000000043, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.96655, "consistency": 0.5613442885917596, "risk_tolerance": 0.7258715832872122, "goal_alignment": 0.5407210461647786, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 8, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.17, "risk_tolerance": -0.03, "consistency": 0.04, "goal_alignment": 0.36}}
{"episode": 8, "reward": -139.09999999999886, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9335169, "consistency": 0.549821600014576, "risk_tolerance": 0.6886198401206378, "goal_alignment": 0.5016094153932494, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 9, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.13, "risk_tolerance": 0.01, "consistency": 0.05, "goal_alignment": 0.4}}
{"episode": 9, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9008998662, "consistency": 0.5384469568145469, "risk_tolerance": 0.6518426004403965, "goal_alignment": 0.46300247023185354, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 10, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.1, "risk_tolerance": 0.05, "consistency": 0.06, "goal_alignment": 0.44}}
{"episode": 10, "reward": -158.8999999999978, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.8686980664676, "consistency": 0.5272200629009178, "risk_tolerance": 0.6155389152395158, "goal_alignment": 0.42489910680082466, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 11, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-taker, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-taker, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.07, "risk_tolerance": 0.08, "consistency": 0.07, "goal_alignment": 0.48}}
{"episode": 11, "reward": -99.49999999999943, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.8369106703346647, "consistency": 0.516140622775116, "risk_tolerance": 0.5797078374090368, "goal_alignment": 0.38729836531263784, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 12, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.04, "risk_tolerance": 0.12, "consistency": 0.08, "goal_alignment": 0.51}}
{"episode": 12, "reward": -202.69999999999973, "steps": 247, "success": "Goal Reached", "identity": {"curiosity": 0.9903368489939954, "consistency": 0.5294083415295657, "risk_tolerance": 0.5443484217342187, "goal_alignment": 0.3916948877155866, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 13, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.19, "risk_tolerance": 0.16, "consistency": 0.07, "goal_alignment": 0.51}}
{"episode": 13, "reward": -59.90000000000062, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9590061752960075, "consistency": 0.5185745248465067, "risk_tolerance": 0.5094597248907502, "goal_alignment": 0.35501371193757514, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 14, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.16, "risk_tolerance": 0.19, "consistency": 0.08, "goal_alignment": 0.54}}
{"episode": 14, "reward": -44.10000000000036, "steps": 443, "success": "Goal Reached", "identity": {"curiosity": 1.0, "consistency": 0.5315373757968137, "risk_tolerance": 0.4750408054409687, "goal_alignment": 0.35778403447557544, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 15, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": 0.22, "consistency": 0.07, "goal_alignment": 0.54}}
{"episode": 15, "reward": -158.89999999999864, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 1.0, "consistency": 0.5209493010452201, "risk_tolerance": 0.44109072383008674, "goal_alignment": 0.32202318338775715, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 16, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.2, "risk_tolerance": 0.26, "consistency": 0.08, "goal_alignment": 0.58}}
{"episode": 16, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9697, "consistency": 0.5105074024431296, "risk_tolerance": 0.40760854238242655, "goal_alignment": 0.2867625571490359, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 17, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.17, "risk_tolerance": 0.29, "consistency": 0.09, "goal_alignment": 0.61}}
{"episode": 17, "reward": -79.69999999999999, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9398105999999999, "consistency": 0.5002113876382434, "risk_tolerance": 0.3745933252976617, "goal_alignment": 0.25199658515534773, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 18, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.14, "risk_tolerance": 0.33, "consistency": 0.1, "goal_alignment": 0.65}}
{"episode": 18, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.9103309788, "consistency": 0.4900609648629669, "risk_tolerance": 0.3420441386470664, "goal_alignment": 0.21772659682998236, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 19, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.11, "risk_tolerance": 0.36, "consistency": 0.11, "goal_alignment": 0.68}}
{"episode": 19, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.8812603168424, "consistency": 0.480055842933241, "risk_tolerance": 0.30996005036977226, "goal_alignment": 0.1839537273312319, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 20, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.08, "risk_tolerance": 0.39, "consistency": 0.12, "goal_alignment": 0.72}}
{"episode": 20, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.8525977962087152, "consistency": 0.4701957312473745, "risk_tolerance": 0.2783401302690327, "goal_alignment": 0.15067479142709733, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 21, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.05, "risk_tolerance": 0.42, "consistency": 0.13, "goal_alignment": 0.75}}
{"episode": 21, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.8243426006162978, "consistency": 0.46048033978487973, "risk_tolerance": 0.24718345000849462, "goal_alignment": 0.11788880125038946, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 22, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": -0.02, "risk_tolerance": 0.45, "consistency": 0.14, "goal_alignment": 0.78}}
{"episode": 22, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.7964939154150652, "consistency": 0.45090937910531, "risk_tolerance": 0.21648908310847761, "goal_alignment": 0.08559477090965338, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 23, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.0, "risk_tolerance": 0.48, "consistency": 0.15, "goal_alignment": 0.81}}
{"episode": 23, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.769050927584235, "consistency": 0.4414825603470994, "risk_tolerance": 0.18625610494226064, "goal_alignment": 0.05378990869888369, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 24, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.03, "risk_tolerance": 0.51, "consistency": 0.16, "goal_alignment": 0.85}}
{"episode": 24, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.7420128257290666, "consistency": 0.43219959522640516, "risk_tolerance": 0.1564835927323761, "goal_alignment": 0.022476851854487438, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 25, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.06, "risk_tolerance": 0.54, "consistency": 0.17, "goal_alignment": 0.88}}
{"episode": 25, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.7153788000776085, "consistency": 0.42306019603595235, "risk_tolerance": 0.12717062554691136, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 26, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.08, "risk_tolerance": 0.57, "consistency": 0.18, "goal_alignment": 0.9}}
{"episode": 26, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.6891480424774532, "consistency": 0.4140640756438805, "risk_tolerance": 0.09831628429581753, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 27, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.11, "risk_tolerance": 0.6, "consistency": 0.19, "goal_alignment": 0.9}}
{"episode": 27, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.6633197463924984, "consistency": 0.40521094749259273, "risk_tolerance": 0.06991965172722589, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 28, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.14, "risk_tolerance": 0.63, "consistency": 0.19, "goal_alignment": 0.9}}
{"episode": 28, "reward": -69.80000000000015, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.6378931068997133, "consistency": 0.3965005255976075, "risk_tolerance": 0.041979812423771426, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 29, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.16, "risk_tolerance": 0.66, "consistency": 0.2, "goal_alignment": 0.9}}
{"episode": 29, "reward": -69.80000000000021, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.6128673206859139, "consistency": 0.38793252454641225, "risk_tolerance": 0.014495852798923878, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 30, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "curious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am curious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.19, "risk_tolerance": 0.69, "consistency": 0.21, "goal_alignment": 0.9}}
{"episode": 30, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.5882415860445421, "consistency": 0.37950665949731943, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 31, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.21, "risk_tolerance": 0.7, "consistency": 0.22, "goal_alignment": 0.9}}
{"episode": 31, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.564015102872453, "consistency": 0.3712226461783248, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 32, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.24, "risk_tolerance": 0.7, "consistency": 0.23, "goal_alignment": 0.9}}
{"episode": 32, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.5401870726667081, "consistency": 0.36308020088596815, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 33, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.26, "risk_tolerance": 0.7, "consistency": 0.24, "goal_alignment": 0.9}}
{"episode": 33, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.5167566985213747, "consistency": 0.3550790404841962, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 34, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.28, "risk_tolerance": 0.7, "consistency": 0.24, "goal_alignment": 0.9}}
{"episode": 34, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.493723185124332, "consistency": 0.34721888240322785, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 35, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.31, "risk_tolerance": 0.7, "consistency": 0.25, "goal_alignment": 0.9}}
{"episode": 35, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.4710857387540833, "consistency": 0.3394994446384214, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 36, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.33, "risk_tolerance": 0.7, "consistency": 0.26, "goal_alignment": 0.9}}
{"episode": 36, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.4488435672765752, "consistency": 0.3319204457491446, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 37, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.35, "risk_tolerance": 0.7, "consistency": 0.27, "goal_alignment": 0.9}}
{"episode": 37, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.42699588014202206, "consistency": 0.32448160485764627, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 38, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.37, "risk_tolerance": 0.7, "consistency": 0.28, "goal_alignment": 0.9}}
{"episode": 38, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.405541888381738, "consistency": 0.317182641647931, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 39, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.39, "risk_tolerance": 0.7, "consistency": 0.28, "goal_alignment": 0.9}}
{"episode": 39, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.3844808046049745, "consistency": 0.3100232763646351, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 40, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.42, "risk_tolerance": 0.7, "consistency": 0.29, "goal_alignment": 0.9}}
{"episode": 40, "reward": -69.8000000000001, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.3638118429957646, "consistency": 0.30300322981190586, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 41, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.44, "risk_tolerance": 0.7, "consistency": 0.3, "goal_alignment": 0.9}}
{"episode": 41, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.34353421930977307, "consistency": 0.29612222335228205, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 42, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.46, "risk_tolerance": 0.7, "consistency": 0.3, "goal_alignment": 0.9}}
{"episode": 42, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.32364715087115353, "consistency": 0.28937997890557754, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 43, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.48, "risk_tolerance": 0.7, "consistency": 0.31, "goal_alignment": 0.9}}
{"episode": 43, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.3041498565694112, "consistency": 0.2827762189477664, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 44, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.5, "risk_tolerance": 0.7, "consistency": 0.32, "goal_alignment": 0.9}}
{"episode": 44, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28504155685627236, "consistency": 0.27631066650987085, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 45, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.51, "risk_tolerance": 0.7, "consistency": 0.32, "goal_alignment": 0.9}}
{"episode": 45, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2663214737425598, "consistency": 0.26998304517685107, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 46, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.7, "consistency": 0.33, "goal_alignment": 0.9}}
{"episode": 46, "reward": -79.69999999999948, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2479888307950747, "consistency": 0.2637930790864974, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 47, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.7, "consistency": 0.34, "goal_alignment": 0.9}}
{"episode": 47, "reward": -99.49999999999861, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23004285313348452, "consistency": 0.2577404929283244, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 48, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.7, "consistency": 0.34, "goal_alignment": 0.9}}
{"episode": 48, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21248276742721756, "consistency": 0.25182501194246776, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 49, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.7, "consistency": 0.35, "goal_alignment": 0.9}}
{"episode": 49, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1953078018923631, "consistency": 0.24604636191858284, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 50, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.7, "consistency": 0.35, "goal_alignment": 0.9}}
{"episode": 50, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17851718628857838, "consistency": 0.24040426919474567, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 51, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.7, "consistency": 0.36, "goal_alignment": 0.9}}
{"episode": 51, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16211015191600123, "consistency": 0.2348984606563562, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 52, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.7, "consistency": 0.37, "goal_alignment": 0.9}}
{"episode": 52, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1460859316121692, "consistency": 0.22952866373504346, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 53, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.7, "consistency": 0.37, "goal_alignment": 0.9}}
{"episode": 53, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13044375974894487, "consistency": 0.2242946064075734, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 54, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.7, "consistency": 0.38, "goal_alignment": 0.9}}
{"episode": 54, "reward": -89.59999999999872, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11518287222944698, "consistency": 0.21919601719475826, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 55, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.7, "consistency": 0.38, "goal_alignment": 0.9}}
{"episode": 55, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10030250648498809, "consistency": 0.21423262516036876, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 56, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.7, "consistency": 0.39, "goal_alignment": 0.9}}
{"episode": 56, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08580190147201812, "consistency": 0.20940415991004802, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 57, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.7, "consistency": 0.39, "goal_alignment": 0.9}}
{"episode": 57, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07168029766907408, "consistency": 0.20471035159022793, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 58, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.7, "consistency": 0.4, "goal_alignment": 0.9}}
{"episode": 58, "reward": -89.5999999999988, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.057936937073735935, "consistency": 0.20015093088704747, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 59, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.7, "consistency": 0.4, "goal_alignment": 0.9}}
{"episode": 59, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.044571063199588465, "consistency": 0.19572562902527338, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 60, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.7, "consistency": 0.4, "goal_alignment": 0.9}}
{"episode": 60, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03158192107318929, "consistency": 0.19143417776722282, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 61, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.7, "consistency": 0.41, "goal_alignment": 0.9}}
{"episode": 61, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.018968757231042903, "consistency": 0.18727630941168838, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 62, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.7, "consistency": 0.41, "goal_alignment": 0.9}}
{"episode": 62, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.006730819716580816, "consistency": 0.183251756792865, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 63, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.7, "consistency": 0.42, "goal_alignment": 0.9}}
{"episode": 63, "reward": -89.59999999999971, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1793602532792793, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 64, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.42, "goal_alignment": 0.9}}
{"episode": 64, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.17560153277272073, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 65, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.42, "goal_alignment": 0.9}}
{"episode": 65, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1719753297071753, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 66, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.43, "goal_alignment": 0.9}}
{"episode": 66, "reward": -129.1999999999987, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.16848137904776095, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 67, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.43, "goal_alignment": 0.9}}
{"episode": 67, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.16511941628966545, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 68, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.43, "goal_alignment": 0.9}}
{"episode": 68, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.16188917745708611, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 69, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.44, "goal_alignment": 0.9}}
{"episode": 69, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.15879039910217196, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 70, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.44, "goal_alignment": 0.9}}
{"episode": 70, "reward": -89.59999999999879, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.15582281830396763, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 71, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.44, "goal_alignment": 0.9}}
{"episode": 71, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1529861726673597, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 72, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.45, "goal_alignment": 0.9}}
{"episode": 72, "reward": -129.19999999999817, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.15028020032202496, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 73, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.45, "goal_alignment": 0.9}}
{"episode": 73, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.14770463992138091, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 74, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.45, "goal_alignment": 0.9}}
{"episode": 74, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.14525923064153815, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 75, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.45, "goal_alignment": 0.9}}
{"episode": 75, "reward": -79.69999999999949, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1429437121802551, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 76, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.46, "goal_alignment": 0.9}}
{"episode": 76, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.14075782475589457, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 77, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.46, "goal_alignment": 0.9}}
{"episode": 77, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1387013091063828, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 78, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.46, "goal_alignment": 0.9}}
{"episode": 78, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.13677390648817, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 79, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.46, "goal_alignment": 0.9}}
{"episode": 79, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.13497535867519367, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 80, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 80, "reward": -109.4000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1333054079578433, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 81, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 81, "reward": -79.69999999999955, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.13176379714192762, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 82, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 82, "reward": -69.80000000000041, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.13035026954764375, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 83, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 83, "reward": -69.8000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12906456900854849, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 84, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 84, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12790643987053138, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 85, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 85, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12687562699079033, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 86, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 86, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12597187573680874, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 87, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 87, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12519493198533513, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 88, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 88, "reward": -79.69999999999932, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12454454212136445, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 89, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 89, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12402045303712171, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 90, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 90, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12362241213104747, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 91, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 91, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12335016730678537, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 92, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 92, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1232034669721718, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 93, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 93, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12318206003822746, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 94, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 94, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.123285695918151, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 95, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 95, "reward": -89.59999999999877, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.1235141245263147, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 96, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 96, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0, "consistency": 0.12386709627726207, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 97, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 97, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 4.9999999999999264e-05, "consistency": 0.12434436208470755, "risk_tolerance": 0.0, "goal_alignment": 0.0, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 98, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 98, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.00044989999999999896, "consistency": 0.12494567336053813, "risk_tolerance": 0.00019999999999999922, "goal_alignment": 0.0003471773332740153, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 99, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.48, "goal_alignment": 0.9}}
{"episode": 99, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0011990001999999987, "consistency": 0.12567078201381704, "risk_tolerance": 0.0007995999999999988, "goal_alignment": 0.0011200951229890658, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 100, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 100, "reward": -69.80000000000017, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0022266021995999987, "consistency": 0.1264944404497894, "risk_tolerance": 0.0017180007999999989, "goal_alignment": 0.0022325720177307595, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 101, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 101, "reward": -79.69999999999935, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.003252148995200799, "consistency": 0.12731645156888985, "risk_tolerance": 0.0026345647983999987, "goal_alignment": 0.003342823869166647, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 102, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 102, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.004275644697210397, "consistency": 0.12813681866575208, "risk_tolerance": 0.0035492956688031986, "goal_alignment": 0.004450860650304633, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 103, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.9}}
{"episode": 103, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.005297093407815977, "consistency": 0.12895554502842058, "risk_tolerance": 0.004462197077465592, "goal_alignment": 0.005556681357880343, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 104, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.7, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 104, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.006316499221000345, "consistency": 0.12977263393836375, "risk_tolerance": 0.005373272683310661, "goal_alignment": 0.006660290424040902, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 105, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 105, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0073338662225583455, "consistency": 0.13058808867048702, "risk_tolerance": 0.006282526137944039, "goal_alignment": 0.0077616922720691395, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 106, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 106, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.008349198490113228, "consistency": 0.13140191249314603, "risk_tolerance": 0.007189961085668151, "goal_alignment": 0.008860891316401321, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 107, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 107, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.009362500093133, "consistency": 0.13221410866815975, "risk_tolerance": 0.008095581163496814, "goal_alignment": 0.009957891962644839, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 108, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 108, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.010373775092946734, "consistency": 0.13302468045082344, "risk_tolerance": 0.00899939000116982, "goal_alignment": 0.01105269860759587, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 109, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 109, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.01138302754276084, "consistency": 0.1338336310899218, "risk_tolerance": 0.009901391221167481, "goal_alignment": 0.012145315639256998, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 110, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 110, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.012390261487675318, "consistency": 0.13464096382774196, "risk_tolerance": 0.010801588438725146, "goal_alignment": 0.013235747436854805, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 111, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.47, "goal_alignment": 0.89}}
{"episode": 111, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.013395480964699967, "consistency": 0.1354466819000865, "risk_tolerance": 0.011699985261847696, "goal_alignment": 0.014323993026968766, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 112, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.46, "goal_alignment": 0.89}}
{"episode": 112, "reward": -69.80000000000014, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.014398690002770567, "consistency": 0.13625078853628633, "risk_tolerance": 0.012596585291324, "goal_alignment": 0.015410062125902499, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 113, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.79, "risk_tolerance": 0.69, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 113, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.015399892622765025, "consistency": 0.13705328695921376, "risk_tolerance": 0.013491392120741352, "goal_alignment": 0.016493959734978095, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 114, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.69, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 114, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.016399092837519495, "consistency": 0.13785418038529534, "risk_tolerance": 0.014384409336499869, "goal_alignment": 0.017575689548835538, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 115, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.69, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 115, "reward": -89.59999999999879, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.017396294651844457, "consistency": 0.13865347202452474, "risk_tolerance": 0.015275640517826868, "goal_alignment": 0.018655255152849756, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 116, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 116, "reward": -59.90000000000056, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.018391502062540768, "consistency": 0.1394511650804757, "risk_tolerance": 0.016165089236791216, "goal_alignment": 0.019732662375871457, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 117, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 117, "reward": -59.90000000000062, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.019384719058415687, "consistency": 0.14024726275031474, "risk_tolerance": 0.017052759058317633, "goal_alignment": 0.020807914784447115, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 118, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 118, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.020375949620298855, "consistency": 0.14104176822481412, "risk_tolerance": 0.017938653540200997, "goal_alignment": 0.02188102138375454, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 119, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 119, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.021365197721058257, "consistency": 0.1418346846883645, "risk_tolerance": 0.018822776233120595, "goal_alignment": 0.02295198176986335, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 120, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 120, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.02235246732561614, "consistency": 0.14262601531898778, "risk_tolerance": 0.019705130680654354, "goal_alignment": 0.02402080023519994, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 121, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.88}}
{"episode": 121, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.023337762390964908, "consistency": 0.1434157632883498, "risk_tolerance": 0.020585720419293043, "goal_alignment": 0.025087481063605862, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 122, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.87}}
{"episode": 122, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.024321086866182978, "consistency": 0.1442039317617731, "risk_tolerance": 0.021464548978454456, "goal_alignment": 0.02615202853035497, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 123, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.78, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.87}}
{"episode": 123, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.02530244469245061, "consistency": 0.14499052389824954, "risk_tolerance": 0.022341619880497546, "goal_alignment": 0.027214446902170578, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 124, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.68, "consistency": 0.46, "goal_alignment": 0.87}}
{"episode": 124, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.02628183980306571, "consistency": 0.14577554285045305, "risk_tolerance": 0.02321693664073655, "goal_alignment": 0.028274740437242554, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 125, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.68, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 125, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.02725927612345958, "consistency": 0.14655899176475215, "risk_tolerance": 0.02409050276745508, "goal_alignment": 0.029332913385244387, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 126, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.68, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 126, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.02823475757121266, "consistency": 0.14734087378122265, "risk_tolerance": 0.02496232176192017, "goal_alignment": 0.03038896464346157, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 127, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.68, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 127, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.029208288056070234, "consistency": 0.1481211920336602, "risk_tolerance": 0.025832397118396327, "goal_alignment": 0.03144290379916232, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 128, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 128, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.030179871479958095, "consistency": 0.14889994964959288, "risk_tolerance": 0.026700732324159534, "goal_alignment": 0.032494735076551665, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 129, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 129, "reward": -79.69999999999979, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03114951173699818, "consistency": 0.1496771497502937, "risk_tolerance": 0.027567330859511213, "goal_alignment": 0.033544462601869905, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 130, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 130, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03211721271352418, "consistency": 0.15045279545079313, "risk_tolerance": 0.028432196197792192, "goal_alignment": 0.03459209610554249, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 131, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.87}}
{"episode": 131, "reward": -79.70000000000036, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.033082978288097135, "consistency": 0.15122688985989155, "risk_tolerance": 0.029295331805396608, "goal_alignment": 0.035637628908802746, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 132, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.86}}
{"episode": 132, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03404681233152094, "consistency": 0.15199943608017177, "risk_tolerance": 0.030156741141785813, "goal_alignment": 0.036681076079861465, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 133, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.77, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.86}}
{"episode": 133, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03500871870685789, "consistency": 0.15277043720801142, "risk_tolerance": 0.03101642765950224, "goal_alignment": 0.03772243166102914, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 134, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.86}}
{"episode": 134, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.035968701269444174, "consistency": 0.1535398963335954, "risk_tolerance": 0.03187439480418324, "goal_alignment": 0.0387617092265834, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 135, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.86}}
{"episode": 135, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.036926763866905285, "consistency": 0.15430781654092823, "risk_tolerance": 0.03273064601457488, "goal_alignment": 0.03979890823700656, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 136, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.67, "consistency": 0.45, "goal_alignment": 0.86}}
{"episode": 136, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.037882910339171474, "consistency": 0.15507420090784638, "risk_tolerance": 0.03358518472254573, "goal_alignment": 0.04083402815385995, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 137, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.67, "consistency": 0.44, "goal_alignment": 0.86}}
{"episode": 137, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03883714451849313, "consistency": 0.1558390525060307, "risk_tolerance": 0.03443801435310064, "goal_alignment": 0.041867082526428546, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 138, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.67, "consistency": 0.44, "goal_alignment": 0.86}}
{"episode": 138, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.03978947022945614, "consistency": 0.15660237440101862, "risk_tolerance": 0.035289138324394446, "goal_alignment": 0.04289806609470309, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 139, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.86}}
{"episode": 139, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.04073989128899723, "consistency": 0.15736416965221658, "risk_tolerance": 0.03613856004774566, "goal_alignment": 0.04392698769584109, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 140, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.86}}
{"episode": 140, "reward": -69.80000000000025, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.041688411506419235, "consistency": 0.15812444131291215, "risk_tolerance": 0.036986282927650174, "goal_alignment": 0.044953850805437075, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 141, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.86}}
{"episode": 141, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.042635034683406396, "consistency": 0.1588831924302863, "risk_tolerance": 0.03783231036179488, "goal_alignment": 0.04597866553270252, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 142, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 142, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.04357976461403958, "consistency": 0.15964042604542575, "risk_tolerance": 0.03867664574107129, "goal_alignment": 0.04700143063051344, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 143, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 143, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.044522605084811505, "consistency": 0.1603961451933349, "risk_tolerance": 0.03951929244958915, "goal_alignment": 0.048022150198128735, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 144, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.76, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 144, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.04546355987464188, "consistency": 0.1611503529029482, "risk_tolerance": 0.04036025386468997, "goal_alignment": 0.0490408283266088, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 145, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 145, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0464026327548926, "consistency": 0.16190305219714232, "risk_tolerance": 0.041199533356960596, "goal_alignment": 0.0500574690988319, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 146, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 146, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.04733982748938281, "consistency": 0.16265424609274803, "risk_tolerance": 0.04203713429024668, "goal_alignment": 0.05107207189396164, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 147, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 147, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.04827514783440405, "consistency": 0.16340393760056254, "risk_tolerance": 0.04287306002166619, "goal_alignment": 0.052084644835161384, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 148, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 148, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.049208597538735244, "consistency": 0.16415212972536142, "risk_tolerance": 0.04370731390162286, "goal_alignment": 0.05309519797436738, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 149, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 149, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.050140180343657775, "consistency": 0.1648988254659107, "risk_tolerance": 0.044539899273819614, "goal_alignment": 0.05410373000729497, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 150, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.66, "consistency": 0.44, "goal_alignment": 0.85}}
{"episode": 150, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05106989998297046, "consistency": 0.1656440278149789, "risk_tolerance": 0.045370819475271974, "goal_alignment": 0.05511024497615671, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 151, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 151, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05199776018300452, "consistency": 0.16638773975934892, "risk_tolerance": 0.046200077836321435, "goal_alignment": 0.05611474691508071, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 152, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 152, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05292376466263851, "consistency": 0.16712996427983023, "risk_tolerance": 0.0470276776806488, "goal_alignment": 0.05711723985012687, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 153, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 153, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05384791713331323, "consistency": 0.16787070435127058, "risk_tolerance": 0.047853622325287504, "goal_alignment": 0.05811772779930294, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 154, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 154, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0547702212990466, "consistency": 0.16860996294256803, "risk_tolerance": 0.04867791508063693, "goal_alignment": 0.059116209428692, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 155, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.75, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 155, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05569068085644851, "consistency": 0.1693477430166829, "risk_tolerance": 0.04950055925047566, "goal_alignment": 0.06011269943871094, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 156, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 156, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05660929949473561, "consistency": 0.17008404753064954, "risk_tolerance": 0.05032155813197471, "goal_alignment": 0.061107196468709844, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 157, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 157, "reward": -59.90000000000062, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05752608089574614, "consistency": 0.17081887943558824, "risk_tolerance": 0.05114091501571077, "goal_alignment": 0.06209969980909982, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 158, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 158, "reward": -89.60000000000015, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.058441028733954646, "consistency": 0.17155224167671707, "risk_tolerance": 0.05195863318567935, "goal_alignment": 0.06309021739259352, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 159, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 159, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.05935414667648674, "consistency": 0.17228413719336363, "risk_tolerance": 0.052774715919308, "goal_alignment": 0.06407875938668464, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 160, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.84}}
{"episode": 160, "reward": -79.7000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.060265438383133765, "consistency": 0.1730145689189769, "risk_tolerance": 0.053589166487469385, "goal_alignment": 0.06506531886338263, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 161, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.83}}
{"episode": 161, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0611749075063675, "consistency": 0.17374353978113896, "risk_tolerance": 0.05440198815449445, "goal_alignment": 0.06604990595898327, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 162, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.65, "consistency": 0.43, "goal_alignment": 0.83}}
{"episode": 162, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06208255769135476, "consistency": 0.17447105270157667, "risk_tolerance": 0.055213184178185465, "goal_alignment": 0.06703252857594162, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 163, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.64, "consistency": 0.43, "goal_alignment": 0.83}}
{"episode": 163, "reward": -69.80000000000014, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06298839257597205, "consistency": 0.17519711059617352, "risk_tolerance": 0.0560227578098291, "goal_alignment": 0.06801318060377741, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 164, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 164, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06389241579082011, "consistency": 0.17592171637498116, "risk_tolerance": 0.05683071229420945, "goal_alignment": 0.06899187667144617, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 165, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 165, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06479463095923847, "consistency": 0.1766448729422312, "risk_tolerance": 0.05763705086962103, "goal_alignment": 0.0699686153469796, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 166, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.74, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 166, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06569504169731999, "consistency": 0.17736658319634674, "risk_tolerance": 0.058441776767881794, "goal_alignment": 0.07094339584961304, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 167, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 167, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06659365161392534, "consistency": 0.17808685002995406, "risk_tolerance": 0.059244893214346034, "goal_alignment": 0.07191623148679013, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 168, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 168, "reward": -139.09999999999877, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0674904643106975, "consistency": 0.17880567632989416, "risk_tolerance": 0.060046403427917346, "goal_alignment": 0.07288711600494872, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 169, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 169, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0683854833820761, "consistency": 0.1795230649772344, "risk_tolerance": 0.060846310621061515, "goal_alignment": 0.07385606420181515, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 170, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 170, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.06927871241531196, "consistency": 0.1802390188472799, "risk_tolerance": 0.06164461799981939, "goal_alignment": 0.07482306980673892, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 171, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.83}}
{"episode": 171, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07017015499048133, "consistency": 0.18095354080958537, "risk_tolerance": 0.06244132876381976, "goal_alignment": 0.07578814140045284, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 172, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.82}}
{"episode": 172, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07105981468050038, "consistency": 0.1816666337279662, "risk_tolerance": 0.06323644610629213, "goal_alignment": 0.07675128754652825, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 173, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.82}}
{"episode": 173, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07194769505113938, "consistency": 0.1823783004605103, "risk_tolerance": 0.06402997321407955, "goal_alignment": 0.0777125027047626, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 174, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.82}}
{"episode": 174, "reward": -59.90000000000058, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07283379966103709, "consistency": 0.18308854385958928, "risk_tolerance": 0.0648219132676514, "goal_alignment": 0.07867179543268048, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 175, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.64, "consistency": 0.42, "goal_alignment": 0.82}}
{"episode": 175, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07371813206171501, "consistency": 0.1837973667718701, "risk_tolerance": 0.0656122694411161, "goal_alignment": 0.07962916957514253, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 176, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.63, "consistency": 0.42, "goal_alignment": 0.82}}
{"episode": 176, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07460069579759158, "consistency": 0.18450477203832638, "risk_tolerance": 0.06640104490223388, "goal_alignment": 0.08058463366486857, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 177, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.73, "risk_tolerance": 0.63, "consistency": 0.42, "goal_alignment": 0.82}}
{"episode": 177, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0754814944059964, "consistency": 0.18521076249424973, "risk_tolerance": 0.06718824281242941, "goal_alignment": 0.08153818682641514, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 178, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.82}}
{"episode": 178, "reward": -59.90000000000046, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07636053141718441, "consistency": 0.18591534096926124, "risk_tolerance": 0.06797386632680455, "goal_alignment": 0.08248982818608971, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 179, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.82}}
{"episode": 179, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07723781035435004, "consistency": 0.1866185102873227, "risk_tolerance": 0.06875791859415094, "goal_alignment": 0.08343957095859385, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 180, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.82}}
{"episode": 180, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07811333473364133, "consistency": 0.18732027326674808, "risk_tolerance": 0.06954040275696263, "goal_alignment": 0.08438741424555297, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 181, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.82}}
{"episode": 181, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.07898710806417406, "consistency": 0.18802063272021458, "risk_tolerance": 0.07032132195144872, "goal_alignment": 0.08533335715038928, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 182, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 182, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0798591338480457, "consistency": 0.18871959145477415, "risk_tolerance": 0.07110067930754582, "goal_alignment": 0.08627741286496482, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 183, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 183, "reward": -51.40000000000034, "steps": 318, "success": "Goal Reached", "identity": {"curiosity": 0.08072941558034961, "consistency": 0.18947215227186462, "risk_tolerance": 0.07187847794893074, "goal_alignment": 0.08731204606464305, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 184, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 184, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08159795674918892, "consistency": 0.1901682079673209, "risk_tolerance": 0.07265472099303288, "goal_alignment": 0.08825214440139008, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 185, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 185, "reward": -79.69999999999948, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08246476083569054, "consistency": 0.19086287155138626, "risk_tolerance": 0.07342941155104682, "goal_alignment": 0.08919035710805866, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 186, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 186, "reward": -89.59999999999978, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08332983131401916, "consistency": 0.19155614580828348, "risk_tolerance": 0.07420255272794472, "goal_alignment": 0.09012669337695443, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 187, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 187, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08419317165139113, "consistency": 0.19224803351666692, "risk_tolerance": 0.07497414762248884, "goal_alignment": 0.09106115772352794, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 188, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.72, "risk_tolerance": 0.63, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 188, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08505478530808835, "consistency": 0.19293853744963357, "risk_tolerance": 0.07574419932724387, "goal_alignment": 0.09199375314140829, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 189, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 189, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08591467573747218, "consistency": 0.1936276603747343, "risk_tolerance": 0.07651271092858938, "goal_alignment": 0.09292448806400179, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 190, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 190, "reward": -89.59999999999881, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08677284638599723, "consistency": 0.19431540505398484, "risk_tolerance": 0.07727968550673221, "goal_alignment": 0.09385335607098567, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 191, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.41, "goal_alignment": 0.81}}
{"episode": 191, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08762930069322523, "consistency": 0.19500177424387688, "risk_tolerance": 0.07804512613571875, "goal_alignment": 0.09478037178772002, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 192, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.81}}
{"episode": 192, "reward": -79.69999999999978, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.08848404209183879, "consistency": 0.19568677069538912, "risk_tolerance": 0.07880903588344731, "goal_alignment": 0.09570552803961593, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 193, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 193, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.0893370740076551, "consistency": 0.19637039715399834, "risk_tolerance": 0.07957141781168042, "goal_alignment": 0.09662883941241301, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 194, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 194, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09018839985963979, "consistency": 0.19705265635969035, "risk_tolerance": 0.08033227497605706, "goal_alignment": 0.0975503041624645, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 195, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 195, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09103802305992051, "consistency": 0.19773355104697096, "risk_tolerance": 0.08109161042610495, "goal_alignment": 0.09846992063912725, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 196, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 196, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09188594701380066, "consistency": 0.19841308394487703, "risk_tolerance": 0.08184942720525275, "goal_alignment": 0.0993876985311764, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 197, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 197, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09273217511977307, "consistency": 0.19909125777698727, "risk_tolerance": 0.08260572835084225, "goal_alignment": 0.10030364556299037, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 198, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 198, "reward": -218.29999999999902, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09357671076953351, "consistency": 0.1997680752614333, "risk_tolerance": 0.08336051689414056, "goal_alignment": 0.10121775525299646, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 199, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 199, "reward": -79.69999999999956, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09441955734799444, "consistency": 0.20044353911091045, "risk_tolerance": 0.08411379586035228, "goal_alignment": 0.10213003673796182, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 200, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.71, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 200, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09526071823329844, "consistency": 0.20111765203268864, "risk_tolerance": 0.08486556826863158, "goal_alignment": 0.10304049909336221, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 201, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.62, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 201, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09610019679683185, "consistency": 0.20179041672862327, "risk_tolerance": 0.08561583713209432, "goal_alignment": 0.10394914052405181, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 202, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 202, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09693799640323819, "consistency": 0.20246183589516603, "risk_tolerance": 0.08636460545783013, "goal_alignment": 0.10485596467188002, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 203, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.4, "goal_alignment": 0.8}}
{"episode": 203, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09777412041043171, "consistency": 0.2031319122233757, "risk_tolerance": 0.08711187624691448, "goal_alignment": 0.10576097517141257, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 204, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.4, "goal_alignment": 0.79}}
{"episode": 204, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09860857216961084, "consistency": 0.20380064839892895, "risk_tolerance": 0.08785765249442065, "goal_alignment": 0.10666417564994606, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 205, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.4, "goal_alignment": 0.79}}
{"episode": 205, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.09944135502527163, "consistency": 0.2044680471021311, "risk_tolerance": 0.08860193718943181, "goal_alignment": 0.10756556972752247, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 206, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.4, "goal_alignment": 0.79}}
{"episode": 206, "reward": -89.59999999999886, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10027247231522109, "consistency": 0.20513411100792683, "risk_tolerance": 0.08934473331505295, "goal_alignment": 0.10846515557117932, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 207, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 207, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10110192737059065, "consistency": 0.20579884278591098, "risk_tolerance": 0.09008604384842285, "goal_alignment": 0.10936294768891328, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 208, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 208, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10192972351584947, "consistency": 0.20646224510033917, "risk_tolerance": 0.09082587176072601, "goal_alignment": 0.11025894422241177, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 209, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 209, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10275586406881777, "consistency": 0.2071243206101385, "risk_tolerance": 0.09156422001720456, "goal_alignment": 0.11115314876284325, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 210, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 210, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10358035234068014, "consistency": 0.2077850719689182, "risk_tolerance": 0.09230109157717015, "goal_alignment": 0.11204556489419389, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 211, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 211, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10440319163599877, "consistency": 0.20844450182498037, "risk_tolerance": 0.0930364893940158, "goal_alignment": 0.11293619084939317, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 212, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.7, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 212, "reward": -79.69999999999999, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10522438525272677, "consistency": 0.2091026128213304, "risk_tolerance": 0.09377041641522778, "goal_alignment": 0.11382503546316573, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 213, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 213, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10604393648222132, "consistency": 0.20975940759568776, "risk_tolerance": 0.09450287558239732, "goal_alignment": 0.11471210782111571, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 214, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.61, "consistency": 0.39, "goal_alignment": 0.79}}
{"episode": 214, "reward": -79.70000000000007, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10686184860925688, "consistency": 0.21041488878049638, "risk_tolerance": 0.09523386983123254, "goal_alignment": 0.11559740060094484, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 215, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 215, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10767812491203836, "consistency": 0.2110690590029354, "risk_tolerance": 0.09596340209157007, "goal_alignment": 0.11648092822861926, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 216, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 216, "reward": -79.69999999999985, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10849276866221429, "consistency": 0.21172192088492953, "risk_tolerance": 0.09669147528738693, "goal_alignment": 0.11736268336763338, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 217, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 217, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.10930578312488985, "consistency": 0.21237347704315968, "risk_tolerance": 0.09741809233681216, "goal_alignment": 0.11824268042977443, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 218, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 218, "reward": -59.90000000000047, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11011717155864008, "consistency": 0.21302373008907335, "risk_tolerance": 0.09814325615213854, "goal_alignment": 0.11912091280224228, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 219, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 219, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1109269372155228, "consistency": 0.21367268262889522, "risk_tolerance": 0.09886696963983427, "goal_alignment": 0.11999738870996521, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 220, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 220, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11173508334109175, "consistency": 0.21432033726363742, "risk_tolerance": 0.0995892357005546, "goal_alignment": 0.12087211636142159, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 221, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 221, "reward": -59.900000000000574, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11254161317440957, "consistency": 0.21496669658911013, "risk_tolerance": 0.1003100572291535, "goal_alignment": 0.12174508986202616, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 222, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.39, "goal_alignment": 0.78}}
{"episode": 222, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11334652994806074, "consistency": 0.21561176319593192, "risk_tolerance": 0.1010294371146952, "goal_alignment": 0.12261632211117843, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 223, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.38, "goal_alignment": 0.78}}
{"episode": 223, "reward": -69.60000000000016, "steps": 401, "success": "Goal Reached", "identity": {"curiosity": 0.11414983688816462, "consistency": 0.21631053966954006, "risk_tolerance": 0.10174737824046581, "goal_alignment": 0.12357689003908721, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 224, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.38, "goal_alignment": 0.78}}
{"episode": 224, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11495153721438829, "consistency": 0.216952918590201, "risk_tolerance": 0.10246388348398489, "goal_alignment": 0.12444445868788535, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 225, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.69, "risk_tolerance": 0.6, "consistency": 0.38, "goal_alignment": 0.78}}
{"episode": 225, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11575163413995951, "consistency": 0.2175940127530206, "risk_tolerance": 0.10317895571701692, "goal_alignment": 0.125310287503837, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 226, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.6, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 226, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11655013087167959, "consistency": 0.21823382472751454, "risk_tolerance": 0.1038925978055829, "goal_alignment": 0.12617438466215672, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 227, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.6, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 227, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11734703060993623, "consistency": 0.21887235707805952, "risk_tolerance": 0.10460481260997173, "goal_alignment": 0.12703675362615982, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 228, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.6, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 228, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11814233654871636, "consistency": 0.2195096123639034, "risk_tolerance": 0.10531560298475179, "goal_alignment": 0.12789740254778384, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 229, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 229, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11893605187561893, "consistency": 0.2201455931391756, "risk_tolerance": 0.10602497177878228, "goal_alignment": 0.1287563301715646, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 230, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 230, "reward": -59.90000000000058, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.11972817977186768, "consistency": 0.22078030195289725, "risk_tolerance": 0.10673292183522472, "goal_alignment": 0.12961353524454888, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 231, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 231, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12051872341232395, "consistency": 0.22141374134899144, "risk_tolerance": 0.10743945599155427, "goal_alignment": 0.1304690306029361, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 232, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 232, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1213076859654993, "consistency": 0.22204591386629347, "risk_tolerance": 0.10814457707957116, "goal_alignment": 0.13132281497060655, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 233, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 233, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1220950705935683, "consistency": 0.22267682203856087, "risk_tolerance": 0.10884828792541203, "goal_alignment": 0.13217489176954167, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 234, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 234, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12288088045238117, "consistency": 0.22330646839448376, "risk_tolerance": 0.1095505913495612, "goal_alignment": 0.1330252644148789, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 235, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 235, "reward": -59.90000000000047, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12366511869147641, "consistency": 0.2239348554576948, "risk_tolerance": 0.11025149016686209, "goal_alignment": 0.13387393161937655, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 236, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 236, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12444778845409346, "consistency": 0.2245619857467794, "risk_tolerance": 0.11095098718652836, "goal_alignment": 0.13472090618501412, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 237, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.68, "risk_tolerance": 0.59, "consistency": 0.38, "goal_alignment": 0.77}}
{"episode": 237, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12522889287718528, "consistency": 0.22518786177528585, "risk_tolerance": 0.11164908521215532, "goal_alignment": 0.1355661821059715, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 238, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.59, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 238, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12600843509143092, "consistency": 0.2258124860517353, "risk_tolerance": 0.11234578704173101, "goal_alignment": 0.13640977217063588, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 239, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.59, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 239, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12678641822124806, "consistency": 0.22643586107963182, "risk_tolerance": 0.11304109546764755, "goal_alignment": 0.13725167035962202, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 240, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.59, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 240, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12756284538480558, "consistency": 0.22705798935747257, "risk_tolerance": 0.11373501327671226, "goal_alignment": 0.1380918847522302, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 241, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.59, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 241, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12833771969403598, "consistency": 0.2276788733787576, "risk_tolerance": 0.11442754325015884, "goal_alignment": 0.13893041871605313, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 242, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.59, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 242, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12911104425464792, "consistency": 0.2282985156320001, "risk_tolerance": 0.11511868816365853, "goal_alignment": 0.13976728030749735, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 243, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 243, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.12988282216613864, "consistency": 0.2289169186007361, "risk_tolerance": 0.11580845078733121, "goal_alignment": 0.1406024681757587, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 244, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 244, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13065305652180637, "consistency": 0.22953408476353462, "risk_tolerance": 0.11649683388575655, "goal_alignment": 0.14143598097273458, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 245, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 245, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13142175040876278, "consistency": 0.23015001659400755, "risk_tolerance": 0.11718384021798503, "goal_alignment": 0.14226783143966543, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 246, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 246, "reward": -69.80000000000055, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13218890690794527, "consistency": 0.23076471656081954, "risk_tolerance": 0.11786947253754906, "goal_alignment": 0.14309801286177376, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 247, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 247, "reward": -69.80000000000005, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1329545290941294, "consistency": 0.2313781871276979, "risk_tolerance": 0.11855373359247397, "goal_alignment": 0.14392653392103788, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 248, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 248, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13371862003594115, "consistency": 0.2319904307534425, "risk_tolerance": 0.11923662612528903, "goal_alignment": 0.14475339858652322, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 249, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.76}}
{"episode": 249, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1344811827958693, "consistency": 0.23260144989193562, "risk_tolerance": 0.11991815287303845, "goal_alignment": 0.1455786095226776, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 250, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.67, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.75}}
{"episode": 250, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13524222043027756, "consistency": 0.23321124699215176, "risk_tolerance": 0.12059831656729238, "goal_alignment": 0.14640217003695966, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 251, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.75}}
{"episode": 251, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.136001735989417, "consistency": 0.23381982449816746, "risk_tolerance": 0.1212771199341578, "goal_alignment": 0.14722408343021315, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 252, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.75}}
{"episode": 252, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1367597325174382, "consistency": 0.23442718484917113, "risk_tolerance": 0.12195456569428949, "goal_alignment": 0.14804435769222904, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 253, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.37, "goal_alignment": 0.75}}
{"episode": 253, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13751621305240333, "consistency": 0.2350333304794728, "risk_tolerance": 0.12263065656290091, "goal_alignment": 0.14886298671017198, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 254, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 254, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13827118062629853, "consistency": 0.23563826381851385, "risk_tolerance": 0.12330539524977512, "goal_alignment": 0.14967997847007905, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 255, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 255, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.13902463826504596, "consistency": 0.23624198729087684, "risk_tolerance": 0.12397878445927557, "goal_alignment": 0.15049534094201522, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 256, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 256, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1397765889885159, "consistency": 0.23684450331629509, "risk_tolerance": 0.12465082689035702, "goal_alignment": 0.1513090726890075, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 257, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.58, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 257, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14052703581053888, "consistency": 0.2374458143096625, "risk_tolerance": 0.1253215252365763, "goal_alignment": 0.15212117697250582, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 258, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 258, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1412759817389178, "consistency": 0.23804592268104316, "risk_tolerance": 0.12599088218610316, "goal_alignment": 0.15293165704743714, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 259, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 259, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14202342977544, "consistency": 0.23864483083568108, "risk_tolerance": 0.12665890042173095, "goal_alignment": 0.15374051146666967, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 260, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 260, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14276938291588914, "consistency": 0.23924254117400973, "risk_tolerance": 0.1273255826208875, "goal_alignment": 0.154547747528724, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 261, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.75}}
{"episode": 261, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14351384415005738, "consistency": 0.2398390560916617, "risk_tolerance": 0.12799093145564572, "goal_alignment": 0.15535337446254288, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 262, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 262, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14425681646175728, "consistency": 0.2404343779794784, "risk_tolerance": 0.12865494959273444, "goal_alignment": 0.15615739014249413, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 263, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 263, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14499830282883377, "consistency": 0.24102850922351943, "risk_tolerance": 0.12931763969354898, "goal_alignment": 0.1569597977910855, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 264, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.66, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 264, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14573830622317613, "consistency": 0.2416214522050724, "risk_tolerance": 0.12997900441416188, "goal_alignment": 0.1577605959288307, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 265, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 265, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1464768296107298, "consistency": 0.24221320930066226, "risk_tolerance": 0.13063904640533355, "goal_alignment": 0.15855979716584936, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 266, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 266, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14721387595150837, "consistency": 0.24280378288206095, "risk_tolerance": 0.13129776831252288, "goal_alignment": 0.15935739530484508, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 267, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 267, "reward": -59.900000000000546, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14794944819960537, "consistency": 0.24339317531629684, "risk_tolerance": 0.13195517277589783, "goal_alignment": 0.1601533982475628, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 268, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 268, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.14868354930320618, "consistency": 0.24398138896566424, "risk_tolerance": 0.13261126243034604, "goal_alignment": 0.16094780918439508, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 269, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 269, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1494161822045998, "consistency": 0.24456842618773292, "risk_tolerance": 0.13326603990548536, "goal_alignment": 0.16174063065101396, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 270, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.36, "goal_alignment": 0.74}}
{"episode": 270, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1501473498401906, "consistency": 0.24515428933535746, "risk_tolerance": 0.13391950782567438, "goal_alignment": 0.16253186712303935, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 271, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.35, "goal_alignment": 0.74}}
{"episode": 271, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15087705514051022, "consistency": 0.24573898075668674, "risk_tolerance": 0.13457166881002303, "goal_alignment": 0.1633215258176696, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 272, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.57, "consistency": 0.35, "goal_alignment": 0.74}}
{"episode": 272, "reward": -69.80000000000025, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1516053010302292, "consistency": 0.24632250279517337, "risk_tolerance": 0.135222525472403, "goal_alignment": 0.16410959985102191, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 273, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.74}}
{"episode": 273, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15233209042816875, "consistency": 0.24690485778958302, "risk_tolerance": 0.13587208042145818, "goal_alignment": 0.16489609838464728, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 274, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.74}}
{"episode": 274, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15305742624731242, "consistency": 0.24748604807400384, "risk_tolerance": 0.13652033626061527, "goal_alignment": 0.16568102861675432, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 275, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 275, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1537813113948178, "consistency": 0.24806607597785585, "risk_tolerance": 0.13716729558809404, "goal_alignment": 0.16646438898839713, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 276, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 276, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15450374877202816, "consistency": 0.24864494382590013, "risk_tolerance": 0.13781296099691787, "goal_alignment": 0.16724618263929666, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 277, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.65, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 277, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15522474127448413, "consistency": 0.24922265393824833, "risk_tolerance": 0.13845733507492403, "goal_alignment": 0.1680264127028944, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 278, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 278, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15594429179193517, "consistency": 0.24979920863037183, "risk_tolerance": 0.1391004204047742, "goal_alignment": 0.16880508230636493, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 279, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 279, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15666240320835131, "consistency": 0.2503746102131111, "risk_tolerance": 0.13974221956396465, "goal_alignment": 0.16958219457062854, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 280, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 280, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15737907840193463, "consistency": 0.2509488609926849, "risk_tolerance": 0.14038273512483673, "goal_alignment": 0.17035774726647496, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 281, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 281, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1580943202451308, "consistency": 0.25152196327069953, "risk_tolerance": 0.14102196965458708, "goal_alignment": 0.17113174885692967, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 282, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 282, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15880813160464055, "consistency": 0.25209391934415815, "risk_tolerance": 0.1416599257152779, "goal_alignment": 0.17190420778809212, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 283, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 283, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.15952051534143127, "consistency": 0.2526647315054698, "risk_tolerance": 0.14229660586384735, "goal_alignment": 0.17267512180139227, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 284, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 284, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1602314743107484, "consistency": 0.2532344020424589, "risk_tolerance": 0.14293201265211966, "goal_alignment": 0.1734444939866658, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 285, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 285, "reward": -59.90000000000053, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16094101136212693, "consistency": 0.253802933238374, "risk_tolerance": 0.14356614862681544, "goal_alignment": 0.1742123227320199, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 286, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 286, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1616491293394027, "consistency": 0.25437032737189724, "risk_tolerance": 0.1441990163295618, "goal_alignment": 0.17497862051543217, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 287, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.73}}
{"episode": 287, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1623558310807239, "consistency": 0.25493658671715347, "risk_tolerance": 0.1448306182969027, "goal_alignment": 0.17574338570327763, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 288, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.56, "consistency": 0.35, "goal_alignment": 0.72}}
{"episode": 288, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16306111941856247, "consistency": 0.25550171354371914, "risk_tolerance": 0.1454609570603089, "goal_alignment": 0.1765066213607474, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 289, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 289, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16376499717972537, "consistency": 0.2560657101166317, "risk_tolerance": 0.1460900351461883, "goal_alignment": 0.17726832585135333, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 290, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 290, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16446746718536592, "consistency": 0.25662857869639843, "risk_tolerance": 0.1467178550758959, "goal_alignment": 0.17802851162852695, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 291, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.64, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 291, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1651685322509952, "consistency": 0.2571903215390056, "risk_tolerance": 0.14734441936574413, "goal_alignment": 0.17878717703414623, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 292, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 292, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16586819518649323, "consistency": 0.2577509408959276, "risk_tolerance": 0.14796973052701265, "goal_alignment": 0.17954432510895427, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 293, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 293, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16656645879612025, "consistency": 0.25831043901413575, "risk_tolerance": 0.14859379106595863, "goal_alignment": 0.1802999588876127, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 294, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 294, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16726332587852802, "consistency": 0.25886881813610746, "risk_tolerance": 0.1492166034838267, "goal_alignment": 0.1810540813987138, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 295, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 295, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16795879922677098, "consistency": 0.25942608049983523, "risk_tolerance": 0.14983817027685906, "goal_alignment": 0.18180669096924376, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 296, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 296, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16865288162831746, "consistency": 0.25998222833883555, "risk_tolerance": 0.15045849393630534, "goal_alignment": 0.1825578000161816, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 297, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 297, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.16934557586506083, "consistency": 0.26053726388215787, "risk_tolerance": 0.15107757694843274, "goal_alignment": 0.18330740684502558, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 298, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 298, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17003688471333073, "consistency": 0.26109118935439357, "risk_tolerance": 0.15169542179453588, "goal_alignment": 0.18405551446021187, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 299, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 299, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17072681094390407, "consistency": 0.2616440069756848, "risk_tolerance": 0.1523120309509468, "goal_alignment": 0.18480212586016778, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 300, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.72}}
{"episode": 300, "reward": -69.8000000000002, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17141535732201627, "consistency": 0.26219571896173344, "risk_tolerance": 0.1529274068890449, "goal_alignment": 0.18554723869343512, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 301, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.71}}
{"episode": 301, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17210252660737224, "consistency": 0.26274632752381, "risk_tolerance": 0.15354155207526682, "goal_alignment": 0.18629086664492459, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 302, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.71}}
{"episode": 302, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17278832155415752, "consistency": 0.2632958348687624, "risk_tolerance": 0.1541544689711163, "goal_alignment": 0.18703300734051106, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 303, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.71}}
{"episode": 303, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17347274491104922, "consistency": 0.2638442431990249, "risk_tolerance": 0.15476616003317406, "goal_alignment": 0.18777366375470636, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 304, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.55, "consistency": 0.34, "goal_alignment": 0.71}}
{"episode": 304, "reward": -59.900000000000496, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17415579942122714, "consistency": 0.2643915547126268, "risk_tolerance": 0.15537662771310773, "goal_alignment": 0.18851283416052436, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 305, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.54, "consistency": 0.34, "goal_alignment": 0.71}}
{"episode": 305, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1748374878223847, "consistency": 0.2649377716032016, "risk_tolerance": 0.15598587445768153, "goal_alignment": 0.1892505262255307, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 306, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.63, "risk_tolerance": 0.54, "consistency": 0.34, "goal_alignment": 0.71}}
{"episode": 306, "reward": -69.80000000000015, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17551781284673995, "consistency": 0.2654828960599952, "risk_tolerance": 0.15659390270876616, "goal_alignment": 0.1899867422580673, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 307, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 307, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17619677722104649, "consistency": 0.2660269302678752, "risk_tolerance": 0.15720071490334864, "goal_alignment": 0.19072149120242748, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 308, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 308, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1768743836666044, "consistency": 0.2665698764073395, "risk_tolerance": 0.15780631347354193, "goal_alignment": 0.19145477064889896, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 309, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 309, "reward": -69.80000000000014, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1775506348992712, "consistency": 0.2671117366545248, "risk_tolerance": 0.15841070084659484, "goal_alignment": 0.19218657819258883, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 310, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 310, "reward": -69.80000000000027, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17822553362947266, "consistency": 0.26765251318121575, "risk_tolerance": 0.15901387944490164, "goal_alignment": 0.19291692212119133, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 311, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 311, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17889908256221373, "consistency": 0.26819220815485334, "risk_tolerance": 0.15961585168601183, "goal_alignment": 0.19364581070582526, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 312, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 312, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.17957128439708933, "consistency": 0.2687308237385436, "risk_tolerance": 0.1602166199826398, "goal_alignment": 0.19437323681774102, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 313, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.71}}
{"episode": 313, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18024214182829518, "consistency": 0.2692683620910665, "risk_tolerance": 0.16081618674267453, "goal_alignment": 0.19509921277298187, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 314, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 314, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1809116575446386, "consistency": 0.2698048253668844, "risk_tolerance": 0.1614145543691892, "goal_alignment": 0.19582373677631223, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 315, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 315, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18157983422954932, "consistency": 0.27034021571615063, "risk_tolerance": 0.16201172526045082, "goal_alignment": 0.19654681173163593, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 316, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 316, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18224667456109023, "consistency": 0.27087453528471833, "risk_tolerance": 0.16260770180992992, "goal_alignment": 0.19726843584150006, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 317, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 317, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18291218121196806, "consistency": 0.2714077862141489, "risk_tolerance": 0.16320248640631008, "goal_alignment": 0.19798861605480472, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 318, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 318, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18357635684954413, "consistency": 0.2719399706417206, "risk_tolerance": 0.16379608143349747, "goal_alignment": 0.1987073565560225, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 319, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 319, "reward": -59.900000000000496, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18423920413584505, "consistency": 0.2724710907004372, "risk_tolerance": 0.1643884892706305, "goal_alignment": 0.19942465957623787, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 320, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 320, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18490072572757338, "consistency": 0.2730011485190363, "risk_tolerance": 0.16497971229208924, "goal_alignment": 0.20014053268596171, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 321, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.62, "risk_tolerance": 0.54, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 321, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18556092427611826, "consistency": 0.2735301462219982, "risk_tolerance": 0.16556975286750505, "goal_alignment": 0.20085497404946612, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 322, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 322, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18621980242756603, "consistency": 0.2740580859295542, "risk_tolerance": 0.16615861336177004, "goal_alignment": 0.20156798653024352, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 323, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 323, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18687736282271092, "consistency": 0.2745849697576951, "risk_tolerance": 0.16674629613504652, "goal_alignment": 0.20227956829051044, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 324, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.33, "goal_alignment": 0.7}}
{"episode": 324, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1875336080970655, "consistency": 0.2751107998181797, "risk_tolerance": 0.16733280354277644, "goal_alignment": 0.20298973158280575, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 325, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.7}}
{"episode": 325, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1881885408808714, "consistency": 0.27563557821854334, "risk_tolerance": 0.16791813793569088, "goal_alignment": 0.20369847454851647, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 326, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.7}}
{"episode": 326, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18884216379910967, "consistency": 0.2761593070621063, "risk_tolerance": 0.1685023016598195, "goal_alignment": 0.20440580002829578, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 327, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.7}}
{"episode": 327, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.18949447947151146, "consistency": 0.2766819884479821, "risk_tolerance": 0.16908529705649986, "goal_alignment": 0.20511171085711552, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 328, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 328, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19014549051256846, "consistency": 0.27720362447108615, "risk_tolerance": 0.16966712646238685, "goal_alignment": 0.20581620986427762, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 329, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 329, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19079519953154334, "consistency": 0.27772421722214397, "risk_tolerance": 0.1702477922094621, "goal_alignment": 0.20651929452953674, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 330, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 330, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19144360913248026, "consistency": 0.2782437687876997, "risk_tolerance": 0.17082729662504317, "goal_alignment": 0.20722097367380507, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 331, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 331, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1920907219142153, "consistency": 0.2787622812501243, "risk_tolerance": 0.1714056420317931, "goal_alignment": 0.2079212541553338, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 332, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 332, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19273654047038688, "consistency": 0.27927975668762406, "risk_tolerance": 0.17198283074772952, "goal_alignment": 0.20862013407589947, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 333, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 333, "reward": -69.80000000000011, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19338106738944613, "consistency": 0.2797961971742488, "risk_tolerance": 0.17255886508623405, "goal_alignment": 0.20931761089273535, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 334, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 334, "reward": -59.900000000000496, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19402430525466724, "consistency": 0.2803116047799003, "risk_tolerance": 0.1731337473560616, "goal_alignment": 0.21001369340427728, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 335, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 335, "reward": -79.69999999999953, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19466625664415793, "consistency": 0.2808259815703405, "risk_tolerance": 0.1737074798613495, "goal_alignment": 0.21070838301294006, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 336, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.61, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 336, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19530692413086964, "consistency": 0.2813393296071998, "risk_tolerance": 0.17428006490162679, "goal_alignment": 0.2114016839802416, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 337, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 337, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19594631028260792, "consistency": 0.2818516509479854, "risk_tolerance": 0.17485150477182354, "goal_alignment": 0.2120935983456085, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 338, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.53, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 338, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1965844176620427, "consistency": 0.28236294764608943, "risk_tolerance": 0.1754218017622799, "goal_alignment": 0.21278413357779363, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 339, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 339, "reward": -69.80000000000021, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19722124882671863, "consistency": 0.28287322175079727, "risk_tolerance": 0.17599095815875535, "goal_alignment": 0.2134732823956257, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 340, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 340, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19785680632906522, "consistency": 0.28338247530729566, "risk_tolerance": 0.17655897624243783, "goal_alignment": 0.2141610582597108, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 341, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 341, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1984910927164071, "consistency": 0.28389071035668106, "risk_tolerance": 0.17712585828995295, "goal_alignment": 0.21484745387651877, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 342, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.32, "goal_alignment": 0.69}}
{"episode": 342, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.1991241105309743, "consistency": 0.2843979289359677, "risk_tolerance": 0.17769160657337305, "goal_alignment": 0.21553248139764206, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 343, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.32, "goal_alignment": 0.68}}
{"episode": 343, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.19975586230991238, "consistency": 0.28490413307809576, "risk_tolerance": 0.1782562233602263, "goal_alignment": 0.2162161388637231, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 344, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.32, "goal_alignment": 0.68}}
{"episode": 344, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20038635058529256, "consistency": 0.2854093248119396, "risk_tolerance": 0.17881971091350587, "goal_alignment": 0.21689842901487197, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 345, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 345, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20101557788412197, "consistency": 0.2859135061623157, "risk_tolerance": 0.17938207149167887, "goal_alignment": 0.21757935458571856, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 346, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 346, "reward": -89.59999999999886, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20164354672835375, "consistency": 0.2864166791499911, "risk_tolerance": 0.1799433073486955, "goal_alignment": 0.218258912859659, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 347, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 347, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20227025963489706, "consistency": 0.2869188457916911, "risk_tolerance": 0.18050342073399814, "goal_alignment": 0.2189371127672671, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 348, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 348, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2028957191156273, "consistency": 0.2874200081001077, "risk_tolerance": 0.18106241389253014, "goal_alignment": 0.21961395627505997, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 349, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 349, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20351992767739605, "consistency": 0.28792016808390747, "risk_tolerance": 0.1816202890647451, "goal_alignment": 0.22028944609583725, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 350, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 350, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20414288782204126, "consistency": 0.28841932774773965, "risk_tolerance": 0.1821770484866156, "goal_alignment": 0.220963584936973, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 351, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 351, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20476460204639718, "consistency": 0.2889174890922442, "risk_tolerance": 0.18273269438964237, "goal_alignment": 0.22163638019597537, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 352, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.6, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 352, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2053850728423044, "consistency": 0.2894146541140597, "risk_tolerance": 0.18328722900086308, "goal_alignment": 0.22230782516891082, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 353, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 353, "reward": -79.69999999999932, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2060043026966198, "consistency": 0.2899108248058316, "risk_tolerance": 0.18384065454286136, "goal_alignment": 0.22297792651404436, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 354, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 354, "reward": -59.900000000000524, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20662229409122657, "consistency": 0.2904060031562199, "risk_tolerance": 0.18439297323377565, "goal_alignment": 0.22364668839434368, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 355, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 355, "reward": -69.80000000000005, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20723904950304411, "consistency": 0.29090019114990745, "risk_tolerance": 0.1849441872873081, "goal_alignment": 0.22431411210254265, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 356, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.52, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 356, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20785457140403804, "consistency": 0.2913933907676076, "risk_tolerance": 0.1854942989127335, "goal_alignment": 0.22498020161166496, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 357, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.68}}
{"episode": 357, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20846886226123, "consistency": 0.2918856039860724, "risk_tolerance": 0.18604331031490803, "goal_alignment": 0.22564496363731795, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 358, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 358, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20908192453670754, "consistency": 0.2923768327781002, "risk_tolerance": 0.18659122369427822, "goal_alignment": 0.22630839613891965, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 359, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 359, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.20969376068763415, "consistency": 0.292867079112544, "risk_tolerance": 0.18713804124688965, "goal_alignment": 0.22697050177551814, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 360, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 360, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21030437316625888, "consistency": 0.2933563449543189, "risk_tolerance": 0.1876837651643959, "goal_alignment": 0.22763128320084344, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 361, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 361, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21091376441992638, "consistency": 0.29384463226441027, "risk_tolerance": 0.1882283976340671, "goal_alignment": 0.2282907430633181, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 362, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 362, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21152193689108653, "consistency": 0.29433194299988147, "risk_tolerance": 0.18877194083879897, "goal_alignment": 0.22894887931051885, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 363, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 363, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21212889301730437, "consistency": 0.2948182791138817, "risk_tolerance": 0.18931439695712138, "goal_alignment": 0.22960569928522523, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 364, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.31, "goal_alignment": 0.67}}
{"episode": 364, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21273463523126976, "consistency": 0.29530364255565394, "risk_tolerance": 0.18985576816320715, "goal_alignment": 0.2302612103155311, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 365, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 365, "reward": -59.90000000000062, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21333916596080724, "consistency": 0.29578803527054265, "risk_tolerance": 0.19039605662688075, "goal_alignment": 0.23091540562822743, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 366, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 366, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21394248762888562, "consistency": 0.2962714592000016, "risk_tolerance": 0.190935264513627, "goal_alignment": 0.23156829190195863, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 367, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 367, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21454460265362787, "consistency": 0.2967539162816016, "risk_tolerance": 0.19147339398459975, "goal_alignment": 0.23221987774703104, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 368, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.59, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 368, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21514551344832064, "consistency": 0.2972354084490384, "risk_tolerance": 0.19201044719663055, "goal_alignment": 0.2328701604204133, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 369, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 369, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21574522242142402, "consistency": 0.2977159376321403, "risk_tolerance": 0.19254642630223728, "goal_alignment": 0.2335191425284488, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 370, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 370, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2163437319765812, "consistency": 0.29819550575687603, "risk_tolerance": 0.19308133344963282, "goal_alignment": 0.2341668219767193, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 371, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 371, "reward": -79.69999999999958, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21694104451262805, "consistency": 0.29867411474536226, "risk_tolerance": 0.19361517078273358, "goal_alignment": 0.23481320532823724, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 372, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.67}}
{"episode": 372, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2175371624236028, "consistency": 0.29915176651587155, "risk_tolerance": 0.19414794044116812, "goal_alignment": 0.2354583013464571, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 373, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 373, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21813208809875562, "consistency": 0.2996284629828398, "risk_tolerance": 0.19467964456028578, "goal_alignment": 0.23610210717264052, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 374, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.51, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 374, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.21872582392255813, "consistency": 0.3001042060568741, "risk_tolerance": 0.1952102852711652, "goal_alignment": 0.23674462069162264, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 375, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 375, "reward": -59.90000000000062, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.219318372274713, "consistency": 0.30057899764476037, "risk_tolerance": 0.19573986470062288, "goal_alignment": 0.2373858491835668, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 376, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 376, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2199097355301636, "consistency": 0.3010528396494708, "risk_tolerance": 0.19626838497122165, "goal_alignment": 0.23802579991407602, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 377, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 377, "reward": -79.69999999999939, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2204999160591033, "consistency": 0.3015257339701719, "risk_tolerance": 0.1967958482012792, "goal_alignment": 0.23866446530971921, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 378, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 378, "reward": -69.80000000000003, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2210889162269851, "consistency": 0.3019976825022316, "risk_tolerance": 0.19732225650487664, "goal_alignment": 0.23930185346408744, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 379, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 379, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22167673839453114, "consistency": 0.30246868713722713, "risk_tolerance": 0.1978476119918669, "goal_alignment": 0.2399379721860356, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 380, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 380, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22226338491774209, "consistency": 0.3029387497629527, "risk_tolerance": 0.19837191676788318, "goal_alignment": 0.24057281867053987, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 381, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 381, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22284885814790661, "consistency": 0.3034078722634268, "risk_tolerance": 0.19889517293434741, "goal_alignment": 0.24120639546207512, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 382, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 382, "reward": -79.70000000000026, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22343316043161082, "consistency": 0.30387605651889993, "risk_tolerance": 0.19941738258847871, "goal_alignment": 0.24183869966662233, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 383, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 383, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2240162941107476, "consistency": 0.30434330440586216, "risk_tolerance": 0.19993854782330175, "goal_alignment": 0.24246974469616542, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 384, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 384, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22459826152252613, "consistency": 0.30480961779705046, "risk_tolerance": 0.20045867072765516, "goal_alignment": 0.2430995276356494, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 385, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.58, "risk_tolerance": 0.5, "consistency": 0.3, "goal_alignment": 0.66}}
{"episode": 385, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2251790649994811, "consistency": 0.30527499856145635, "risk_tolerance": 0.20097775338619986, "goal_alignment": 0.24372805100925443, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 386, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.66}}
{"episode": 386, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22575870686948216, "consistency": 0.30573944856433344, "risk_tolerance": 0.20149579787942745, "goal_alignment": 0.24435531733611227, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 387, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.66}}
{"episode": 387, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22633718945574322, "consistency": 0.3062029696672048, "risk_tolerance": 0.2020128062836686, "goal_alignment": 0.24498132443476744, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 388, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.66}}
{"episode": 388, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22691451507683175, "consistency": 0.30666556372787035, "risk_tolerance": 0.20252878067110128, "goal_alignment": 0.2456060795192253, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 389, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 389, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2274906860466781, "consistency": 0.30712723260041463, "risk_tolerance": 0.20304372310975907, "goal_alignment": 0.24622958978906317, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 390, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 390, "reward": -69.80000000000031, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22806570467458476, "consistency": 0.3075879781352138, "risk_tolerance": 0.20355763566353957, "goal_alignment": 0.24685184769447271, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 391, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 391, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2286395732652356, "consistency": 0.3080478021789434, "risk_tolerance": 0.2040705203922125, "goal_alignment": 0.2474728664279601, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 392, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 392, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22921229411870514, "consistency": 0.3085067065745855, "risk_tolerance": 0.20458237935142806, "goal_alignment": 0.24809263778009183, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 393, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.5, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 393, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.22978386953046775, "consistency": 0.3089646931614363, "risk_tolerance": 0.2050932145927252, "goal_alignment": 0.24871117023785905, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 394, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 394, "reward": -59.90000000000053, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23035430179140684, "consistency": 0.30942176377511343, "risk_tolerance": 0.20560302816353976, "goal_alignment": 0.24932846563071073, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 395, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 395, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23092359318782404, "consistency": 0.3098779202475632, "risk_tolerance": 0.20611182210721268, "goal_alignment": 0.24994453112832563, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 396, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 396, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23149174600144842, "consistency": 0.3103331644070681, "risk_tolerance": 0.20661959846299827, "goal_alignment": 0.25055936449494526, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 397, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 397, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23205876250944554, "consistency": 0.31078749807825395, "risk_tolerance": 0.20712635926607229, "goal_alignment": 0.25117296819483165, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 398, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 398, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23262464498442667, "consistency": 0.31124092308209744, "risk_tolerance": 0.20763210654754014, "goal_alignment": 0.2517853399917694, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 399, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 399, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23318939569445782, "consistency": 0.31169344123593323, "risk_tolerance": 0.20813684233444507, "goal_alignment": 0.25239649174066214, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 400, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 400, "reward": -89.59999999999881, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2337530169030689, "consistency": 0.31214505435346135, "risk_tolerance": 0.20864056864977618, "goal_alignment": 0.2530064157402927, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 401, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 401, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23431551086926278, "consistency": 0.31259576424475444, "risk_tolerance": 0.20914328751247663, "goal_alignment": 0.25361512533768843, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 402, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 402, "reward": -59.400000000000574, "steps": 497, "success": "Goal Reached", "identity": {"curiosity": 0.23487687984752426, "consistency": 0.3131005727162649, "risk_tolerance": 0.20964500093745167, "goal_alignment": 0.254312639751334, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 403, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.57, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 403, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2354371260878292, "consistency": 0.3135493715708324, "risk_tolerance": 0.21014571093557677, "goal_alignment": 0.25491873690070765, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 404, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.65}}
{"episode": 404, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23599625183565356, "consistency": 0.31399727282769074, "risk_tolerance": 0.2106454195137056, "goal_alignment": 0.25552361716023364, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 405, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.64}}
{"episode": 405, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23655425933198226, "consistency": 0.31444427828203536, "risk_tolerance": 0.2111441286746782, "goal_alignment": 0.2561272876592406, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 406, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.64}}
{"episode": 406, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23711115081331832, "consistency": 0.3148903897254713, "risk_tolerance": 0.21164184041732884, "goal_alignment": 0.2567297508172495, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 407, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.29, "goal_alignment": 0.64}}
{"episode": 407, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2376669285116917, "consistency": 0.31533560894602036, "risk_tolerance": 0.21213855673649418, "goal_alignment": 0.2573310137444913, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 408, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 408, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23822159465466833, "consistency": 0.31577993772812835, "risk_tolerance": 0.2126342796230212, "goal_alignment": 0.2579310741458786, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 409, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 409, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.238775151465359, "consistency": 0.31622337785267207, "risk_tolerance": 0.21312901106377516, "goal_alignment": 0.25852993442646316, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 410, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 410, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2393276011624283, "consistency": 0.3166659310969667, "risk_tolerance": 0.2136227530416476, "goal_alignment": 0.2591275922909376, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 411, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 411, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.23987894596010345, "consistency": 0.3171075992347728, "risk_tolerance": 0.2141155075355643, "goal_alignment": 0.25972405953523203, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 412, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 412, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24042918806818325, "consistency": 0.31754838403630326, "risk_tolerance": 0.21460727652049316, "goal_alignment": 0.26031932914948896, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 413, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.49, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 413, "reward": -69.8000000000001, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2409783296920469, "consistency": 0.31798828726823064, "risk_tolerance": 0.21509806196745218, "goal_alignment": 0.2609134075761777, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 414, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 414, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24152637303266283, "consistency": 0.3184273106936942, "risk_tolerance": 0.21558786584351727, "goal_alignment": 0.26150629784601304, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 415, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 415, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24207332028659753, "consistency": 0.3188654560723068, "risk_tolerance": 0.21607669011183026, "goal_alignment": 0.26209800298364844, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 416, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 416, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24261917364602434, "consistency": 0.3193027251601622, "risk_tolerance": 0.2165645367316066, "goal_alignment": 0.26268852471100856, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 417, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 417, "reward": -59.90000000000058, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24316393529873231, "consistency": 0.3197391197098419, "risk_tolerance": 0.2170514076581434, "goal_alignment": 0.26327786539491393, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 418, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 418, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24370760742813485, "consistency": 0.32017464147042224, "risk_tolerance": 0.21753730484282713, "goal_alignment": 0.2638660273974515, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 419, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 419, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2442501922132786, "consistency": 0.3206092921874814, "risk_tolerance": 0.2180222302331415, "goal_alignment": 0.2644530177715329, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 420, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.64}}
{"episode": 420, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24479169182885205, "consistency": 0.32104307360310647, "risk_tolerance": 0.21850618577267522, "goal_alignment": 0.2650388341648661, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 421, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.56, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 421, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24533210844519435, "consistency": 0.3214759874559003, "risk_tolerance": 0.21898917340112986, "goal_alignment": 0.2656234789254127, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 422, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 422, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24587144422830398, "consistency": 0.3219080354809885, "risk_tolerance": 0.2194711950543276, "goal_alignment": 0.2662069543964382, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 423, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 423, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24640970133984738, "consistency": 0.3223392194100265, "risk_tolerance": 0.21995225266421894, "goal_alignment": 0.26678926291652166, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 424, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 424, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2469468819371677, "consistency": 0.32276954097120647, "risk_tolerance": 0.2204323481588905, "goal_alignment": 0.2673704068195649, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 425, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 425, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2474829881732934, "consistency": 0.32319900188926404, "risk_tolerance": 0.22091148346257272, "goal_alignment": 0.26795038843480207, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 426, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 426, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24801802219694682, "consistency": 0.3236276038854855, "risk_tolerance": 0.22138966049564757, "goal_alignment": 0.26852920539125985, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 427, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 427, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24855198615255295, "consistency": 0.3240553486777145, "risk_tolerance": 0.22186688117465628, "goal_alignment": 0.26910686940935363, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 428, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 428, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24908488218024785, "consistency": 0.3244822379803591, "risk_tolerance": 0.22234314741230696, "goal_alignment": 0.26968337809941123, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 429, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 429, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.24961671241588737, "consistency": 0.3249082735043984, "risk_tolerance": 0.22281846111748235, "goal_alignment": 0.2702587337720887, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 430, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.28, "goal_alignment": 0.63}}
{"episode": 430, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2501474789910556, "consistency": 0.3253334569573896, "risk_tolerance": 0.2232928241952474, "goal_alignment": 0.27083293873342085, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 431, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 431, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2506771840330735, "consistency": 0.3257577900434748, "risk_tolerance": 0.2237662385468569, "goal_alignment": 0.2714059952848303, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 432, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 432, "reward": -89.59999999999874, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2512058296650073, "consistency": 0.3261812744633879, "risk_tolerance": 0.22423870606976318, "goal_alignment": 0.2719779002773725, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 433, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 433, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2517334180056773, "consistency": 0.32660391191446114, "risk_tolerance": 0.22471022865762366, "goal_alignment": 0.27254866690569407, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 434, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.48, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 434, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25225995116966593, "consistency": 0.3270257040906322, "risk_tolerance": 0.22518080820030842, "goal_alignment": 0.2731182873052101, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 435, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 435, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2527854312673266, "consistency": 0.32744665268245093, "risk_tolerance": 0.22565044658390782, "goal_alignment": 0.273686773159476, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 436, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 436, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2533098604047919, "consistency": 0.32786675937708604, "risk_tolerance": 0.22611914569074001, "goal_alignment": 0.2742541220420333, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 437, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 437, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25383324068398233, "consistency": 0.3282860258583319, "risk_tolerance": 0.22658690739935855, "goal_alignment": 0.27482033153127666, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 438, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.63}}
{"episode": 438, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25435557420261434, "consistency": 0.3287044538066152, "risk_tolerance": 0.22705373358455982, "goal_alignment": 0.27538541329709043, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 439, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 439, "reward": -69.80000000000013, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2548768630542091, "consistency": 0.329122044899002, "risk_tolerance": 0.2275196261173907, "goal_alignment": 0.27594935955548394, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 440, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.55, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 440, "reward": -59.90000000000055, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25539710932810067, "consistency": 0.329538800809204, "risk_tolerance": 0.22798458686515594, "goal_alignment": 0.2765121785697004, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 441, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 441, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25591631510944446, "consistency": 0.3299547232075856, "risk_tolerance": 0.22844861769142563, "goal_alignment": 0.2770738766414373, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 442, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 442, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25643448247922557, "consistency": 0.33036981376117047, "risk_tolerance": 0.22891172045604277, "goal_alignment": 0.27763445131703074, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 443, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 443, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2569516135142671, "consistency": 0.33078407413364813, "risk_tolerance": 0.2293738970151307, "goal_alignment": 0.2781939001477241, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 444, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 444, "reward": -69.80000000000018, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2574677102872385, "consistency": 0.33119750598538084, "risk_tolerance": 0.22983514922110043, "goal_alignment": 0.27875222943241634, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 445, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 445, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25798277486666404, "consistency": 0.3316101109734101, "risk_tolerance": 0.23029547892265823, "goal_alignment": 0.2793094474024278, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 446, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 446, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2584968093169307, "consistency": 0.33202189075146327, "risk_tolerance": 0.23075488796481292, "goal_alignment": 0.27986555093649923, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 447, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 447, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25900981569829684, "consistency": 0.33243284696996034, "risk_tolerance": 0.2312133781888833, "goal_alignment": 0.28042054226350255, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 448, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 448, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.25952179606690023, "consistency": 0.3328429812760204, "risk_tolerance": 0.23167095143250555, "goal_alignment": 0.28097442360785185, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 449, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 449, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2600327524747664, "consistency": 0.3332522953134684, "risk_tolerance": 0.23212760952964054, "goal_alignment": 0.28152719718951247, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 450, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 450, "reward": -79.69999999999949, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26054268696981686, "consistency": 0.33366079072284144, "risk_tolerance": 0.23258335431058125, "goal_alignment": 0.2820788597906048, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 451, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 451, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2610516015958772, "consistency": 0.33406846914139576, "risk_tolerance": 0.2330381876019601, "goal_alignment": 0.2826294244998999, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 452, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 452, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26155949839268544, "consistency": 0.334475332203113, "risk_tolerance": 0.23349211122675617, "goal_alignment": 0.2831788880797764, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 453, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 453, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26206637939590005, "consistency": 0.3348813815387068, "risk_tolerance": 0.23394512700430267, "goal_alignment": 0.28372724803694427, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 454, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.27, "goal_alignment": 0.62}}
{"episode": 454, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2625722466371082, "consistency": 0.3352866187756294, "risk_tolerance": 0.23439723675029406, "goal_alignment": 0.2842745112741978, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 455, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.26, "goal_alignment": 0.62}}
{"episode": 455, "reward": -59.90000000000062, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26307710214383395, "consistency": 0.3356910455380781, "risk_tolerance": 0.23484844227679347, "goal_alignment": 0.2848206799849768, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 456, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.47, "consistency": 0.26, "goal_alignment": 0.62}}
{"episode": 456, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2635809479395463, "consistency": 0.33609466344700195, "risk_tolerance": 0.23529874539223988, "goal_alignment": 0.2853657610538831, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 457, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 457, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26408378604366717, "consistency": 0.33649747412010794, "risk_tolerance": 0.2357481479014554, "goal_alignment": 0.28590975196065166, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 458, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 458, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2645856184715798, "consistency": 0.33689947917186774, "risk_tolerance": 0.2361966516056525, "goal_alignment": 0.2864526501900578, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 459, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.54, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 459, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26508644723463665, "consistency": 0.337300680213524, "risk_tolerance": 0.2366442583024412, "goal_alignment": 0.28699446262300504, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 460, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 460, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26558627434016735, "consistency": 0.33770107885309697, "risk_tolerance": 0.23709096978583633, "goal_alignment": 0.2875351961266353, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 461, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 461, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.266085101791487, "consistency": 0.3381006766953908, "risk_tolerance": 0.23753678784626467, "goal_alignment": 0.28807484816325835, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 462, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 462, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26658293158790397, "consistency": 0.33849947534200003, "risk_tolerance": 0.23798171427057213, "goal_alignment": 0.2886134208958081, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 463, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 463, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.26707976572472814, "consistency": 0.338897476391316, "risk_tolerance": 0.238425750842031, "goal_alignment": 0.28915091178734387, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 464, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 464, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2675756061932787, "consistency": 0.33929468143853336, "risk_tolerance": 0.23886889934034694, "goal_alignment": 0.2896873323926455, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 465, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 465, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2680704549808921, "consistency": 0.3396910920756563, "risk_tolerance": 0.23931116154166626, "goal_alignment": 0.29022267546118763, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 466, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 466, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2685643140709303, "consistency": 0.34008670989150497, "risk_tolerance": 0.23975253921858294, "goal_alignment": 0.2907569478435927, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 467, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 467, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2690571854427884, "consistency": 0.34048153647172197, "risk_tolerance": 0.24019303414014578, "goal_alignment": 0.2912901563767818, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 468, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 468, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2695490710719028, "consistency": 0.34087557339877855, "risk_tolerance": 0.2406326480718655, "goal_alignment": 0.29182229849290453, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 469, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 469, "reward": -109.39999999999884, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27003997292975895, "consistency": 0.341268822251981, "risk_tolerance": 0.24107138277572177, "goal_alignment": 0.2923533708770885, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 470, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 470, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2705298929838994, "consistency": 0.3416612846074771, "risk_tolerance": 0.24150924001017032, "goal_alignment": 0.29288338656421065, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 471, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 471, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2710188331979316, "consistency": 0.34205296203826213, "risk_tolerance": 0.24194622153015, "goal_alignment": 0.29341233752440965, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 472, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 472, "reward": -89.5999999999991, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27150679553153567, "consistency": 0.3424438561141856, "risk_tolerance": 0.2423823290870897, "goal_alignment": 0.29394022983247275, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 473, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 473, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2719937819404726, "consistency": 0.34283396840195723, "risk_tolerance": 0.24281756442891553, "goal_alignment": 0.29446706710613524, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 474, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 474, "reward": -69.80000000000027, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27247979437659164, "consistency": 0.3432233004651533, "risk_tolerance": 0.2432519293000577, "goal_alignment": 0.29499285005691067, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 475, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.61}}
{"episode": 475, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27296483478783845, "consistency": 0.343611853864223, "risk_tolerance": 0.2436854254414576, "goal_alignment": 0.29551758678567314, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 476, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.6}}
{"episode": 476, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27344890511826275, "consistency": 0.34399963015649454, "risk_tolerance": 0.2441180545905747, "goal_alignment": 0.2960412740409781, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 477, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.6}}
{"episode": 477, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2739320073080262, "consistency": 0.34438663089618154, "risk_tolerance": 0.24454981848139357, "goal_alignment": 0.2965639139217724, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 478, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.6}}
{"episode": 478, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27441414329341013, "consistency": 0.3447728576343892, "risk_tolerance": 0.2449807188444308, "goal_alignment": 0.29708550852280513, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 479, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.46, "consistency": 0.26, "goal_alignment": 0.6}}
{"episode": 479, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2748953150068233, "consistency": 0.34515831191912044, "risk_tolerance": 0.24541075740674193, "goal_alignment": 0.29760605993463585, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 480, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.53, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 480, "reward": -59.9000000000006, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2753755243768096, "consistency": 0.3455429952952822, "risk_tolerance": 0.24583993589192846, "goal_alignment": 0.298125565548094, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 481, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 481, "reward": -59.90000000000061, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27585477332805597, "consistency": 0.34592690930469167, "risk_tolerance": 0.2462682560201446, "goal_alignment": 0.2986440321503252, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 482, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 482, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2763330637813998, "consistency": 0.3463100554860823, "risk_tolerance": 0.24669571950810432, "goal_alignment": 0.29916146651490083, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 483, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 483, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.276810397653837, "consistency": 0.34669243537511013, "risk_tolerance": 0.2471223280690881, "goal_alignment": 0.2996778660107473, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 484, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 484, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2772867768585293, "consistency": 0.3470740505043599, "risk_tolerance": 0.24754808341294993, "goal_alignment": 0.3001932280120532, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 485, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 485, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2777622033048122, "consistency": 0.3474549024033512, "risk_tolerance": 0.24797298724612402, "goal_alignment": 0.30070756398490545, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 486, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 486, "reward": -99.49999999999972, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2782366788982026, "consistency": 0.3478349925985445, "risk_tolerance": 0.24839704127163176, "goal_alignment": 0.30122086583834107, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 487, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 487, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27871020554040615, "consistency": 0.3482143226133474, "risk_tolerance": 0.2488202471890885, "goal_alignment": 0.3017331465355407, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 488, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 488, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2791827851293253, "consistency": 0.3485928939681207, "risk_tolerance": 0.24924260669471032, "goal_alignment": 0.302244397975797, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 489, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 489, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.27965441955906667, "consistency": 0.3489707081801845, "risk_tolerance": 0.24966412148132092, "goal_alignment": 0.3027546316087217, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 490, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 490, "reward": -79.69999999999948, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2801251107199485, "consistency": 0.3493477667638241, "risk_tolerance": 0.25008479323835825, "goal_alignment": 0.3032638393409756, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 491, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 491, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28059486049850857, "consistency": 0.3497240712302965, "risk_tolerance": 0.25050462365188153, "goal_alignment": 0.30377203409117, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 492, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 492, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28106367077751154, "consistency": 0.3500996230878359, "risk_tolerance": 0.2509236144045777, "goal_alignment": 0.30427920775631506, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 493, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 493, "reward": -59.90000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2815315434359565, "consistency": 0.3504744238416602, "risk_tolerance": 0.25134176717576856, "goal_alignment": 0.30478536707412984, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 494, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.6}}
{"episode": 494, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28199848034908453, "consistency": 0.3508484749939769, "risk_tolerance": 0.251759083641417, "goal_alignment": 0.3052905187688579, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 495, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.59}}
{"episode": 495, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28246448338838637, "consistency": 0.35122177804398896, "risk_tolerance": 0.25217556547413417, "goal_alignment": 0.30579466016019646, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 496, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.59}}
{"episode": 496, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28292955442160955, "consistency": 0.351594334487901, "risk_tolerance": 0.2525912143431859, "goal_alignment": 0.3062977932687524, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 497, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.59}}
{"episode": 497, "reward": -89.59999999999917, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.2833936953127663, "consistency": 0.3519661458189252, "risk_tolerance": 0.2530060319144995, "goal_alignment": 0.3067999146653268, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 498, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.59}}
{"episode": 498, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28385690792214074, "consistency": 0.35233721352728736, "risk_tolerance": 0.2534200198506705, "goal_alignment": 0.30730103726487246, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 499, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.59}}
{"episode": 499, "reward": -50.00000000000044, "steps": 500, "success": "Max Steps", "identity": {"curiosity": 0.28431919410629647, "consistency": 0.3527075391002328, "risk_tolerance": 0.2538331798109691, "goal_alignment": 0.307801157619219, "intent": "explore", "priors": {"curiosity": 0.55, "consistency": 0.55, "risk_tolerance": 0.5, "goal_alignment": 0.6}, "cfg": {"adapt_lr": 0.05, "decay": 0.002, "min_v": 0.0, "max_v": 1.0, "eps_base": 0.1, "bias_base": 0.5, "gate_sim_thr": 0.6, "gate_conf_thr": 0.6, "no_regret_margin": 0.15, "novelty_bonus": 0.1, "map_gap_bonus": 0.08, "plasticity_anneal": 0.0005}, "episodes": 500, "ideal_self": {"curiosity": 0.8, "risk_tolerance": 0.7, "consistency": 0.6, "goal_alignment": 0.9}}, "symbolic_description": "cautious, risk-averse, adaptive, drifter", "narrative": "I act as an explore agent because I am cautious, risk-averse, adaptive, drifter.", "gap_to_ideal": {"curiosity": 0.52, "risk_tolerance": 0.45, "consistency": 0.25, "goal_alignment": 0.59}}
